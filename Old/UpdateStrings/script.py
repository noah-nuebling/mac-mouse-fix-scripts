
"""

This script helps to keep .strings files in sync with source code and IB files.
It's a replacement for bartycrouch.

Manual testing steps:

- [x] Remove semicolon on a kv-pair
    -> Should throw an error, and not write anything
- [x] Multiline values like addField hint (N7H-9j-DIr.title) don't duplicate or anything

- [x] Insert key in source file
    - Test both IB and code source file (insert in code using NSLocalizedString)
    -> Result: String shows up in .strings file with correct comment and empty value. (Localizable.strings is for source code)
- [x] Delete autogenerated comment in .strings file, Add inline comment, add value, reorder
    - Test both IB and code source file
    -> Result: Inline comment and value are preserved. Order and autogenerated comment are restored. (It's important to preserve inline comments for our !IS_OK flags)
    ->      Currently 03.01.2024 this sometimes deletes surrounding values. But I can't reproduce this despite best efforts. Very strange.
- [x] Add superfluous kv-pair, add comment above
    -> Result: Superfluous kv-pair is moved to start of file, comment is preserved
    
- [x] StateOfLocalization doesn't change after this updates everything.

"""

#
# Native imports
#

import sys
import os
from pprint import pprint
import argparse

import cProfile

#
# Import functions from ../Shared folder
#

code_dir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
if code_dir not in sys.path:
    sys.path.append(code_dir)
from Shared import shared

#
# Constants
#

temp_folder = './update_comments_temp'

#
# Main
#

def main():
    
    # Create temp dir
    shared.runCLT(f"mkdir -p {temp_folder}")
    
    try:
    
        # Args
        parser = argparse.ArgumentParser()
        parser.add_argument('--wet_run', required=False, action='store_true', help="Provide this arg to actually modify files. Otherwise it will just log what it would do.", default=False)
        args = parser.parse_args()
        
        # Constants & stuff
        repo_root = os.getcwd()
        assert os.path.basename(repo_root) == 'mac-mouse-fix', "Run this script from the 'mac-mouse-fix' repo folder."
        
        # Find files
        ib_files = shared.find_localization_files(repo_root, None, ['IB'])
        strings_files = shared.find_localization_files(repo_root, None, ['strings'])
        
        # Get updates to .strings files
        updated_files_ib, modss_ib = update_strings_files(ib_files, 'IB', repo_root)
        updated_files_src, modss_src = update_strings_files(strings_files, 'sourcecode', repo_root)
        updated_files = updated_files_ib + updated_files_src
        
        # Log
        #   Note: This stuff doesn't work very well. Just look at git diff
        
        # print(f"\nLogging all modifications that have been found...") 
        # log_modifications(modss_src)
        # log_modifications(modss_ib)
        
        # Write 
        if args.wet_run and len(updated_files) > 0:
            print('\n\n')
            for w in updated_files:
                print(f"Writing to file at {w['path']}...")
                shared.write_file(w['path'], w['new_content'])
        else:
            print(f"\n\nNot writing anything. {len(updated_files_ib)} ib files and {len(updated_files_src)} src files with updates. Is dry run: {not args.wet_run}.")
        
        # Debug
        # pprint(ib_files)
        # pprint(strings_files)
    
    finally:
        
        # Print
        print("Done! Cleaning up temp folder and exiting...")
        
        # Clean up
        shared.runCLT(f"rm -R ./{temp_folder}")
    
#
# Update .strings files
#

def update_strings_files(files, type, repo_root):
    
    """
    (if type == 'sourcecode')   Update .strings files to match source code files which they translate
    (if type == 'IB')           Update .strings files to match .xib/.storyboard files which they translate
    
    Discussion:
    
    - On location of English (development language) UI strings:
        
        Explanation:
        - For IB, the English strings are directly in the source (IB) files
            (This isn't the case for every Xcode project, but we chose do t the case for the MMF project.)
        - On the other hand, for sourcecode, the English strings not directly in the source (sourcecode) files, instead they are inside en.lproj/Localizable.strings.
        
        Thoughts:
        - In update_ib_comments we don't update English .strings files - because currently in MMF there are no English .strings files for IB files - that's because the IB files hold the English UI strings directly.
        - Maybe we should've specified development language values directly in the source code using `NSLocalizedStringWithDefaultValue` instead of inside en.lproj. That way we wouldn't need en.lproj at all.
        - Not sure anymore why we chose to do it with en.lproj instead of all source code for English. But either way, I don't think it's worth it to change now.
    """
    
    print(f"\nUpdating strings files type {type}...")
    
    assert type in ['sourcecode', 'IB'], f"UpdateStrings script is incorrect."
    if type == 'sourcecode': xcassert(len(files) == 1, "There should only be one base .strings file - Localizable.strings")
    
    updated_files = [] # This is for updating files
    modss = [] # This is for debugging
    
    for file_dict in files:
    
        # Get generate_content
        #   Explanation:
        #   - What we do here is first autogenerate fresh .strings file from the source files (IB/sourcecode) using Apples tools
        #   - The fresh strings files will have their kv-pair's comments and keys up-to-date with the source file (but it won't contain any translations, the values are just empty or garbage)
        #   - We store the content of these freshly generated strings files inside generated_content
        
        generated_content = ''
        
        if type == 'sourcecode':
            source_code_files = shared.find_files_with_extensions(['m','c','cp','mm','swift'], ['env/', 'venv/', 'iOS-Polynomial-Regression-master/', './Test/'])
            source_code_files_str = ' '.join(map(lambda p: p.replace(' ', r'\ '), source_code_files))
            shared.runCLT(f"xcrun extractLocStrings {source_code_files_str} -SwiftUI -o ./{temp_folder}", exec='/bin/zsh')
            generated_path = f"{temp_folder}/Localizable.strings"
            generated_content = shared.read_file(generated_path, 'utf-16')
        elif type == 'IB':
            base_file_path = file_dict['base']
            generated_path = shared.extract_strings_from_IB_file_to_temp_file(base_file_path)
            generated_content = shared.read_tempfile(generated_path)
        else: 
            assert False
        
        # Find all the .strings files that translate the source files
        translation_file_paths = list(file_dict['translations'].keys())
        if type == 'sourcecode':
            translation_file_paths.append(file_dict['base'])
        
        for path in translation_file_paths:
                
            # Update the translation .strings file
            #   using the keys and comments of the generated .strings file
            content = shared.read_file(path, 'utf-8')
            new_content, mods, ordered_keys = updated_strings_file_content(content, generated_content, path, repo_root)
            
            # Store updates
            if new_content != content:
                updated_files.append({"path": path, "new_content": new_content})
            
            # Debug
            modss.append({'path': path, 'mods': mods, 'ordered_keys': ordered_keys})

    # Return
    return updated_files, modss
    
        
        

#
# Debug helper
#

def log_modifications(modss):
    
    """
    Notes:
    - We wrote this to be able to see what exactly our code did. But it's bad and not really used. I think I just went over to using a diff tool to see what changed instead of this.
    - Not sure if show_line_numbers in shared.get_diff_string is useful. the line number isn't the line number in the source file
        but instead it's the position of the kv-pair in the list of kv-pairs in the source file.
    """
    
    result = ''
    
    for mods in modss:
        
        path_result = ''
        
        keys_before = '\n'.join(mods['ordered_keys']['before'])
        keys_after = '\n'.join(mods['ordered_keys']['after'])
        keys_diff = shared.get_diff_string(keys_before, keys_after, filter_unchanged_lines=False, show_line_numbers=True)
        
        if len(keys_diff) > 0:
            if False: # This sucks. Just use git diff.
                path_result += f"\n\n    Key order diff:\n{shared.add_indent(keys_diff, 8)}"
            else: 
                path_result += f"\\n\n    The order of keys seems to have changed. (I think - this might be broken)"
                
        for mod in sorted(mods['mods'], key=lambda x: x['modtype'], reverse=True):
            
            key = mod['key']
            modtype = mod['modtype']
            if modtype == 'comment':
                
                b = mod['before'].strip()
                a = mod['after'].strip()
                
                if a == b:
                    path_result += f"\n\n    {key}'s comment whitespace changed"    
                else:
                    a = shared.add_indent(a, 8)
                    b = shared.add_indent(b, 8)
                    
                    path_result += f"\n\n    {key} comment changed:\n{b}\n        ->\n{a}"
                
            elif modtype == 'insert':
                value = shared.add_indent(mod['value'], 8)
                path_result += f"\n\n    {key} was inserted:\n{value}"
                
            else: 
             assert False
        
        if len(path_result) > 0:
            result += f"\n\n{mods['path']} was modified:{path_result}\n"
        else:
            result += f"\n{mods['path']} was not modified"
    
    if len(result) > 0:
        print(result)
            
    
    
#
# String parse & modify
#

def updated_strings_file_content(content, generated_content, file_path, repo_root):
    
    """
    What this does at time of writing:
    - Copy over all comments from `generated_content` to `content`
    - Insert kv-pair + comment from `generated_content` into `content` - if the kv-pair is not found in `content`
    - Reorder kv-pairs in `content` to match `generated_content`
    """
    
    # Parse both contents
    #   Notes:
    #   - We can use remove_value=True, to remove autogenerated values of kv-pairs inside generated_content.
    #       - generated_content is created by one of Apples command line tools. Either by `extractLocStrings` for sourcecode files or by `ibtool` for IB files. `extractLocStrings` seems to set the values equal to the keys, while `ibtool` seems to set the values equal to the base language (English in our case) values
    #   - Update: I think it's better to keep the autogenerated values. Makes it more clear to users that 'this string is not translated' instead of having no text at all which can look broken in some cases.
    
    parse = parse_strings_file_content(content, file_path)
    generated_parse = parse_strings_file_content(generated_content, file_path, remove_value=False)
    
    # Record modifications for diagnositics
    mods = []
    
    for key in generated_parse.keys():
    
        is_missing = key not in parse        
        p = None if is_missing else parse[key]
        g = generated_parse[key]
        
        # Replace line sep
        #   Notes: 
        #   - line separators (unicode U+2028) are generated by `ibtool` but don't display properly on GitHub and other places, and \n works the same and is much easier for translators to enter.
        #   - Update: I can't reproduce ibtool generating U+2028. It generates \n by itself. No idea how the U+2028 happened. In some post I read that Xcode randomly sometimes generates \n and others times U+2028?
        
        lsep = "\u2028"
        g['comment'] = g['comment'].replace(lsep, r'\n')

        if is_missing:
            
            # Insert kv-pair
            parse[key] = g
            mods.append({'key': key, 'modtype': 'insert', 'value': g['comment'] + g['line']})
            
        else:
            
            # Replace comment
            if p['comment'] != g['comment']:
                mods.append({'key': key, 'modtype': 'comment', 'before': p['comment'], 'after': g['comment']})
                p['comment'] = g['comment']
    
    # Validate parse
    
    all_keys = set(parse.keys()).union(set(generated_parse.keys())) # For debugging
    for l in all_keys:
        l_comment = parse[l]['comment']
        for k in all_keys: # Idea: you could also check if the key appears in single\double quotes, or after linebreak to increase confidence that something is broken.
            assert f"{k}" not in l_comment, f"The key {k} appears in the comment for key {l}. Something is probably broken in the parsing code. Not proceeding. Comment:\n\n{parse[l]['comment']}\n\n"
    
    # Reassemple parse into updated content
    
    new_content = ''
    
    # Get new keys in order
    # Notes: 
    # - First, we attach unused kv-pairs, 
    #   so they are visible because they might need action
    # - Second, we attach kv-pairs that also occur in generated_content
    #   Note: dict.keys() are in insertion order in python. Therefore, this should synchronize the order of kv-pairs in the new_content with the generated_content
    
    generated_keys = list(generated_parse.keys())
    superfluous_keys = [k for k in parse.keys() if k not in generated_parse.keys()]
    new_keys = superfluous_keys + generated_keys
    
    # Attach
    
    for k in superfluous_keys:
        
        new_content += parse[k]['comment']
        new_content += parse[k]['line']
        
        if '/en' in file_path or '/Base' in file_path: # I think checking for 'Base' here is unnecessary.
            line_number = len(new_content.split('\n')) - 1
            xcwarn("This key isn't used in any source code files. Consider removing it from the development language Localizable.strings file. Explanation: The StateOfLocalization script compares translated Localizable.strings files against the development language Localizable.strings file and discrepancies are automatically published in the StateOfLocalization comment. So the developer only has to keep the development language Localizable.strings file in sync with the source code and the rest can be done by translators.",
                           f"{file_path}", f"{line_number}")
        
    for i, k in enumerate(generated_keys):
        
        # Note: the generated source code strings files (Localized.strings) don't have a leading linebreak, but the IB strings files do. Insert linebreak here to make things look nicer.
        if i == 0 and not parse[k]['comment'].startswith('\n'): 
            new_content += '\n'
        
        # Attach main content
        new_content += parse[k]['comment']
        new_content += parse[k]['line']
        
    # Analyze reordering
    ordered_key_dict = {
        'before': parse.keys(),
        'after': new_keys
    }
    
    # Return
    return new_content, mods, ordered_key_dict
    
    

def parse_strings_file_content(content, file_path, remove_value=False):
    
    """
    
    Parse a .strings file into this structure:      (Should also work on .js translation files such as the ones we're using on the nuxt MMF website, but that's currently untested)
    {
        "<translation_key>": {
            "comment": "<comment_string>",
            "line": "<translation_key_and_value_string>",
        },
        ...
    }
    
    Notes:
    - See shared.strings_file_regex() for context.
    """
    
    result = {}
    
    kv_regex        = shared.strings_file_regex_kv_line()
    comment_regex   = shared.strings_file_regex_comment_line()
    blank_regex     = shared.strings_file_regex_blank_line()
    
    
    #
    # Approach 1: Line-based approach
    #
    
    """
    Notes:
    - On the line-based approach vs match-based approach:
        - line-based approach:
            - goes through the text line-by line, and applies the regex to each line.
            - That makes for simple code, and it allows us to verify that the .strings file has the correct format, instead of doing weird stuff like the match-based approach.
            - We used splitlines(True) to iterate lines, but this didn't work, because the strings sometimes contain the character 'LINE SEPARATOR' (U+2028) if you enter a linebreak in IB, and splitlines() splits at those characters. (Example for this is the '+' field hint, which used to contain the LINE SEPARATOR char.)
                - Note: Gave GitHub Feedback at: https://github.com/orgs/community/discussions/84092
            - But by simply using .split('\n') it seems to work!
        - match-based approach:
            - The match-based approach applies a regex for finding kv-pairs to the whole string, and then iterates through the matches.
            - This works fine, butttt if you forget to put a semicolon at the end, then it will consider the whole kv-pair part of a comment, and will simply delete it.
                This has happened to me a few times when I was tired and I HATE this behaviour. That's why we're going back to the line-based approach with some additional checks to make sure everything is well-formatted. So we can give user feedback if there's a syntax error in the strings file instead of just deleting stuff.
    - Somehow we seem to be replacing consecutive blank lines before and after comments with single blank lines in the output of the script.
        That's nice, but I don't understand why it's happending. Might be coming from this function. Edit: It think it's just because we replace the comments. And the comments from the generated content don't have double line breaks.
    """
    
    def assert_full_match(match, line, regex_name, line_number):
    
        """
        Explanation:
        We want every character of every line to be matched by one of our regexes. That way we can be more sure that the syntax of each line is correct and our code correctly parses each line. This function checks of every character of line is matched by a specific regex.
        """
    
        match_end_target = 0 if len(line) == 0 else len(line) - 1
        
        if not (match.start(0) == 0 and match.end(0) == match_end_target):
            xcerror(f"Line is matched by {regex_name}, but only partially. This means there is probably something weird with the syntax / formatting.",
                           file_path, line_number)
    
    last_key_line_number = -1
    last_key = ''
    acc_comment = ''

    lines = content.split('\n')
    for i, line in enumerate(lines): # `True` preserves linebreaks, so that we can easily stitch everything together exactly as it was.
        
        if i != len(lines) - 1:
            line += '\n'
        
        kv_match = kv_regex.match(line)

        if kv_match:
            
            assert_full_match(kv_match, line, 'kv_regex', i+1)

            key = kv_match.group(2)
            if remove_value:
                value_start = kv_match.start(3)
                value_end = kv_match.end(3)
                result_line = line[:value_start] + line[value_end:]
            else:
                result_line = line

            result[key] = { "line": result_line, "comment": acc_comment }
            acc_comment = ''

            last_key = key
            last_key_line_number = i+1
        else:
            comment_match = comment_regex.match(line)
            blank_match = blank_regex.match(line)
            
            if comment_match:
                assert_full_match(comment_match, line, 'comment_regex', i+1)
            elif blank_match:
                assert_full_match(blank_match, line, 'blank_regex', i+1)
            else:
                xcerror(f"Line doesn't match kv, comment, or blank line regex. That means there's probably something weird with the syntax / formatting.", file_path, i+1)
            
            acc_comment += line 

    post_comment = acc_comment
    if not len(post_comment.strip()) == 0: xcerror(f"There's content under the last key-value-pair (this line). Don't know what to do with that. Pls remove?", file_path, last_key_line_number)
    
    return result
    
    #
    # Approach 2: Match-based
    #
    
    last_match = None
    last_key = ''
    
    matches = list(regex.finditer(content))
    
    for match in matches:
        
        comment_start = last_match.end(0) if last_match else 0
        comment_end = match.start(0)
        comment = content[comment_start:comment_end]
        
        line_start = match.start(0)
        line_end = match.end(0)
        line = match.group(0)
        
        key = match.group(2)
        
        result_line = ''
        if remove_value:
            value_start = match.start(3)
            value_end = match.end(3)
            result_line = content[line_start:value_start] + content[value_end:line_end]
        else:
            result_line = line
        
        assert key not in result, f"There's a duplicate key {key}"
        result[key] = { "line": result_line, "comment": comment }
        
        last_key = key
        last_match = match
        
    last_match = matches[-1]
    assert len(content.rstrip()) == last_match.end(0), f"There's content under the last key {last_key}. Don't know what to do with that. Pls remove."
    
    
    return result

#
# Xcode 
#

# Note: We're using this script as part of the Xcode build process of MMF. With these functions we can display errors and warnings directly in Xcode!

def xcassert(condition, message, file='', line=''):
    if not condition:
        xcerror(file, line, message)

def xcerror(message, file='', line=''):
    print("\nPrinting error for Xcode and then aborting...")
    xcode_message("error", file, line, message, flush=True)
    exit(1)

def xcwarn(message, file='', line=''):
    print("\nPrinting warning for Xcode...")
    xcode_message("warning", file, line, message)

def xcode_message(type, file, line, message, flush=False):
    # Type can be "note", "warning", or "error"
    print(f"{file}:{line}: {type}: MMF UpdateStrings script: {message}", flush=flush)

#
# Call main
#

if __name__ == "__main__": 
    # cProfile.run('main()')
    main()
    
    
